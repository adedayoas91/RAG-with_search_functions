# RAG System with Search v1.2

A production-ready Retrieval-Augmented Generation (RAG) system with flexible document sourcing, parallel processing, and a comprehensive testing infrastructure. This system is designed to answer questions based on a given context, which it can source from the web or local files.

**Latest Updates:**
- âœ… **LangChain 1.x compatibility** - Updated to modern LangChain APIs
- âœ… **95 passing tests** - Comprehensive test coverage across all modules
- âœ… **GitHub Actions CI/CD** - Automated testing and quality checks
- âœ… **UV package manager** - Fast, reliable dependency management

## âœ¨ Key Features

### ğŸ”„ Flexible Document Sources
- **Online Search**: Fetch up to 100 sources from the web (articles, PDFs, YouTube).
- **Local Upload**: Load documents from your local filesystem.
- **Hybrid Mode**: Combine both online and local sources.

### ğŸš€ Performance Optimized
- Parallel document downloading (5 workers).
- Ray-based parallel chunking (4 workers).
- Distributed embedding generation.
- Efficient vector storage with ChromaDB.

### ğŸ“Š Advanced Features
- Source filtering by relevance.
- Interactive source approval.
- Numeric citations [1], [2,3], [2-5].
- Real-time cost tracking.
- Session analytics.

### ğŸ§ª Production Ready
- Comprehensive test suite (95 tests - 80 unit, 15 integration).
- GitHub Actions CI/CD pipeline with automated testing.
- 46% code coverage (continuously improving).
- Type checking with Pyright and linting with Ruff.

## ğŸ”„ System Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USER QUERY    â”‚
â”‚  "What is AI?"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DOCUMENT SOURCE â”‚â”€â”€â”€â”€â–¶â”‚  MODE SELECTION â”‚
â”‚   SELECTION     â”‚     â”‚ â€¢ ğŸŒ Online     â”‚
â”‚ â€¢ Online        â”‚     â”‚ â€¢ ğŸ“ Local      â”‚
â”‚ â€¢ Local         â”‚     â”‚ â€¢ ğŸ”„ Both       â”‚
â”‚ â€¢ Both          â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  DOCUMENT GATHERING â”‚
                    â”‚                     â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚ ONLINE  â”‚ LOCAL   â”‚ â”‚
                    â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
                    â”‚ â”‚ Tavily  â”‚ File    â”‚ â”‚
                    â”‚ â”‚ Search  â”‚ Scan    â”‚ â”‚
                    â”‚ â”‚ Filter  â”‚ Load    â”‚ â”‚
                    â”‚ â”‚ Downloadâ”‚         â”‚ â”‚
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  DOCUMENT PROCESSING â”‚
                    â”‚                     â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ CHUNK   â”‚ EMBED   â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚ Split   â”‚ Vector  â”‚ â”‚
â”‚ â”‚ Text    â”‚ Store   â”‚ â”‚
â”‚ â”‚ (80)    â”‚ (Chroma)â”‚ â”‚
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    RETRIEVAL        â”‚
                    â”‚                     â”‚
                    â”‚ â€¢ Similarity Search â”‚
                    â”‚ â€¢ Top-K Results     â”‚
                    â”‚ â€¢ Context Assembly  â”‚
                    â”‚                     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   GENERATION        â”‚
                    â”‚                     â”‚
                    â”‚ â€¢ GPT-4 Answer      â”‚
                    â”‚ â€¢ Citation Links    â”‚
                    â”‚ â€¢ Cost Tracking     â”‚
                    â”‚                     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FINAL RESPONSE    â”‚
                    â”‚                     â”‚
                    â”‚ "AI is... [1][2][3]"â”‚
                    â”‚                     â”‚
                    â”‚ Sources: [1] paper.pdf â”‚
                    â”‚         [2] article.html â”‚
                    â”‚         [3] research.pdf â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow Steps:

1. **Query Input** â†’ User provides research question
2. **Source Selection** â†’ Choose online, local, or both document sources
3. **Document Gathering** â†’ Collect relevant documents based on selection
4. **Processing Pipeline** â†’ Chunk text â†’ Generate embeddings â†’ Store in vector DB
5. **Retrieval** â†’ Find most relevant document chunks using similarity search
6. **Generation** â†’ Synthesize answer with citations using retrieved context
7. **Response** â†’ Deliver formatted answer with source references

## ğŸ“‹ Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Document Source Modes](#document-source-modes)
- [Configuration](#configuration)
- [Usage Examples](#usage-examples)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [API Keys](#api-keys)
- [Contributing](#contributing)

## ğŸ”§ Installation

### Prerequisites

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) package manager

### Install Dependencies

```bash
# Clone the repository
git clone <repository-url>
cd rag-with_search

# Install dependencies with uv
uv sync

# Create .env file with your API keys
echo "OPENAI_API_KEY=your_openai_api_key" > .env
echo "TAVILY_API_KEY=your_tavily_api_key" >> .env
```

### Required API Keys

Add these to your `.env` file:

```env
OPENAI_API_KEY=your_openai_api_key
TAVILY_API_KEY=your_tavily_api_key
```

## ğŸš€ Quick Start

### Basic Usage

```bash
uv run main.py
```

### Example Session

```
What would you like to research? Machine learning fundamentals

How would you like to gather documents for your research?
  1. ğŸŒ Search online (web articles, PDFs, YouTube videos)
  2. ğŸ“ Upload local documents (PDFs, text files)
  3. ğŸ”„ Both (combine online search + local documents)

Enter your choice (1/2/3): 1

[System searches, filters, and presents sources...]
[You approve sources...]
[System processes and generates answer with citations...]
```

## ğŸ“š Document Source Modes

### 1. Online Search Mode

Search and retrieve documents from the web.

**Features:**
- Tavily search (up to 100 sources)
- Relevance filtering
- Source summarization
- User approval workflow
- Automatic download/parsing

**Supported sources:**
- Web articles (parsed HTML)
- PDF documents (downloaded)
- YouTube videos (transcripts)

### 2. Local Upload Mode

Load documents from your local filesystem.

**Features:**
- Directory scanning (recursive optional)
- File preview before loading
- Automatic format detection
- No internet required

**Supported formats:**
- PDF files (`.pdf`)
- Text files (`.txt`)
- Markdown files (`.md`)

**Example:**
```bash
# Create a documents directory
mkdir my_documents
cp *.pdf my_documents/

# Run the system and choose option 2
uv run main.py
# Enter: my_documents/
```

### 3. Hybrid Mode (Both)

Combine online search with local documents.

**Features:**
- All online search features
- All local upload features
- Combined document analysis
- Comprehensive knowledge base

**Best for:**
- Academic research (online papers + personal notes)
- Corporate knowledge (public data + internal docs)
- Validation (cross-reference sources)

See [DOCUMENT_SOURCES.md](DOCUMENT_SOURCES.md) for detailed documentation.

## âš™ï¸ Configuration

### Edit `config.py`

```python
# Search settings
max_results = 100
relevance_threshold = 0.7

# Chunking
chunk_size = 80
chunk_overlap = 20

# Retrieval
retrieval_k = 10

# Models
generation_model = "gpt-4o-mini"
embedding_model = "text-embedding-3-small"
```

### Environment Variables

```env
# Required
OPENAI_API_KEY=sk-...
TAVILY_API_KEY=tvly-...

# Optional
CHUNK_SIZE=1000
RETRIEVAL_K=10
```

## ğŸ’¡ Usage Examples

### Example 1: Research with Online Sources

```bash
uv run main.py
```
```
Query: Latest developments in quantum computing
Mode: 1 (Online)
â†’ System fetches 100 sources
â†’ Filters to 30 relevant sources
â†’ You approve 15 sources
â†’ Downloads/parses articles
â†’ Generates comprehensive answer
```

### Example 2: Analyze Local Documents

```bash
uv run main.py
```
```
Query: Summarize key findings from my research papers
Mode: 2 (Local)
Path: ~/Documents/research/
â†’ Scans directory
â†’ Finds 20 PDFs
â†’ Loads all documents
â†’ Generates summary with citations
```

### Example 3: Hybrid Research

```bash
uv run main.py
```
```
Query: Compare machine learning frameworks
Mode: 3 (Both)
â†’ Searches online (12 sources approved)
â†’ Loads local docs (8 PDFs)
â†’ Analyzes 20 combined documents
â†’ Generates comprehensive comparison
```

### Example 4: Try the Sample Documents

```bash
uv run main.py
```
```
Query: What features does the RAG system support?
Mode: 2 (Local)
Path: ./example_documents
â†’ Loads sample_document.txt
â†’ Generates answer about system features
```

## ğŸ§ª Testing

### Run Tests

```bash
# Run all tests
uv run python -m pytest tests/ -v

# Run unit tests only
uv run python -m pytest tests/unit -v

# Run integration tests only
uv run python -m pytest tests/integration -v

# Run with coverage
uv run python -m pytest tests/ --cov=src --cov-report=html --cov-report=term

# View coverage report
open htmlcov/index.html
```

### Test Suite

- **95 total tests** (all passing âœ…)
  - 80 unit tests
  - 15 integration tests
- **Test coverage**: 46% (improving toward 70% target)
- **CI/CD**: GitHub Actions on every push/PR to main/dev branches

See [tests/README.md](tests/README.md) for detailed testing documentation.

## ğŸ“ Project Structure

```
RAG-with_search_functions/
â”œâ”€â”€ main.py                      # Main entry point
â”œâ”€â”€ config.py                    # Configuration
â”œâ”€â”€ .env                         # API keys (create from .env.example)
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ DOCUMENT_SOURCES.md         # Document source modes guide
â”œâ”€â”€ TESTING_SUMMARY.md          # Testing infrastructure overview
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/              # Document loading and processing
â”‚   â”‚   â”œâ”€â”€ web_search.py       # Tavily search client
â”‚   â”‚   â”œâ”€â”€ local_document_loader.py  # Local file loading
â”‚   â”‚   â”œâ”€â”€ article_downloader.py     # Parallel downloading
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # PDF extraction
â”‚   â”‚   â”œâ”€â”€ text_loader.py      # Text file loading
â”‚   â”‚   â”œâ”€â”€ yt_bot.py           # YouTube transcripts
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Document chunking
â”‚   â”‚   â”œâ”€â”€ google_search.py    # Google search integration
â”‚   â”‚   â”œâ”€â”€ source_filter.py    # Source relevance filtering
â”‚   â”‚   â”œâ”€â”€ source_summarizer.py # Source summarization
â”‚   â”‚   â””â”€â”€ article_loader.py   # Article processing
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/             # Answer generation
â”‚   â”‚   â”œâ”€â”€ agent.py            # LangChain agent setup
â”‚   â”‚   â”œâ”€â”€ answer_generator.py # RAG answer generation
â”‚   â”‚   â”œâ”€â”€ generate.py         # Generation pipeline
â”‚   â”‚   â””â”€â”€ tools.py            # Agent tools
â”‚   â”‚
â”‚   â”œâ”€â”€ search/                 # Search functionality
â”‚   â”‚   â”œâ”€â”€ search_agent.py     # Search agent
â”‚   â”‚   â””â”€â”€ search_tools.py     # Search tools
â”‚   â”‚
â”‚   â”œâ”€â”€ vectorstore/            # Embeddings and vector storage
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # OpenAI embeddings
â”‚   â”‚   â”œâ”€â”€ chroma_store.py     # ChromaDB integration
â”‚   â”‚   â””â”€â”€ parallel_embedding.py  # Ray parallelization
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ cost_tracker.py     # API cost tracking
â”‚       â”œâ”€â”€ cli_display.py      # User interface
â”‚       â”œâ”€â”€ data_persistence.py # Data persistence
â”‚       â””â”€â”€ logging_config.py   # Logging setup
â”‚
â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ unit/                   # Unit tests (79 tests)
â”‚   â”œâ”€â”€ integration/            # Integration tests (17 tests)
â”‚   â”œâ”€â”€ conftest.py            # Shared fixtures
â”‚   â””â”€â”€ README.md              # Testing documentation
â”‚
â”œâ”€â”€ example_documents/          # Sample documents for testing
â”‚   â””â”€â”€ sample_document.txt
â”‚
â”œâ”€â”€ data/                       # Data directory (created at runtime)
â”‚   â”œâ”€â”€ downloads/             # Downloaded articles
â”‚   â”œâ”€â”€ chroma_db/            # Vector database
â”‚   â””â”€â”€ analytics.json        # Session analytics
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml             # GitHub Actions CI/CD
```

## ğŸ”‘ API Keys

### OpenAI API Key

1. Sign up at [platform.openai.com](https://platform.openai.com)
2. Navigate to API Keys
3. Create new secret key
4. Add to `.env` file

**Cost estimates:**
- Embeddings: ~$0.0001 per query
- Generation: ~$0.0006 per 1K output tokens
- Typical session: $0.10-$0.30

### Tavily API Key

1. Sign up at [tavily.com](https://tavily.com)
2. Get API key from dashboard
3. Add to `.env` file

**Features:**
- 100 searches per month (free tier)
- Advanced search depth
- Paywall detection
- Source metadata

## ğŸ’° Cost Tracking

The system tracks API costs in real-time:

- OpenAI API calls (embeddings + generation)
- Tavily search calls
- Per-session breakdown
- Historical analytics

View costs at end of each session or in `data/cost_log.json`.

## ğŸš¦ CI/CD Pipeline

### GitHub Actions Workflow âœ…

- **Test Job**: Runs on Python 3.12 with UV package manager
- **Lint Job**: Code formatting with Ruff
- **Type Check Job**: Static type analysis with Pyright
- **Build Job**: Package verification and import testing

### Current Status
- âœ… **All tests passing** (95/95)
- âœ… **Coverage reports** generated automatically
- âœ… **Multi-stage pipeline** with proper dependencies

### Triggers

- Push to `main`, `dev` branches
- Pull requests to `main`, `dev` branches

See [.github/workflows/ci.yml](.github/workflows/ci.yml) for configuration.

## ğŸ› Troubleshooting

### Common Issues

**"No module named 'src'"**
```bash
# Run from project root with uv
uv run main.py
```

**"Missing API keys"**
```bash
# Check .env file exists and has keys
cat .env
```

**"Ray failed to start"**
```bash
# Check Ray is installed
uv sync
```

**"No supported documents found"** (Local mode)
```bash
# Check file extensions and path
ls -R your_documents_directory/
```

## ğŸ¤ Contributing

### Development Setup

```bash
# Install dev dependencies
uv sync

# Run tests
uv run python -m pytest tests/ -v

# Run linting
uv run ruff check src/ tests/

# Run type checking
uv run pyright src/
```

### Adding Features

1. Create feature branch
2. Write tests first (TDD)
3. Implement feature
4. Ensure tests pass
5. Submit pull request

### Code Style

- Follow PEP8
- Add type hints
- Write docstrings
- Keep functions focused

## ğŸ“œ License

[Add your license here]

## ğŸ™ Acknowledgments

- **OpenAI** for GPT models and embeddings API
- **Tavily** for advanced web search API
- **ChromaDB** for efficient vector storage
- **Ray** for distributed processing and parallelization
- **LangChain 1.x** for modern RAG framework and document processing
- **UV** for fast, reliable Python package management
- **GitHub Actions** for CI/CD automation

## ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Check existing documentation
- Review test examples
